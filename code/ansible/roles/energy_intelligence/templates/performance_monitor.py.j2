#!/usr/bin/env python3
"""
Performance Monitor - Moniteur de performance du syst√®me IA
File: {{ energy_ai_paths.base | default('/opt/energy-ai') }}/performance_monitor.py
Generated by Ansible - Energy Intelligence Role
"""

import json
import time
import subprocess
import psutil
import sys
from datetime import datetime
import requests

def check_system_resources():
    """V√©rification des ressources syst√®me"""
    print("üíª Ressources syst√®me")
    print("-" * 20)
    
    # CPU
    cpu_percent = psutil.cpu_percent(interval=1)
    cpu_count = psutil.cpu_count()
    print(f"üîß CPU: {cpu_percent:.1f}% ({cpu_count} cores)")
    
    # M√©moire
    memory = psutil.virtual_memory()
    print(f"üíæ RAM: {memory.percent:.1f}% ({memory.used // (1024**3):.1f}GB / {memory.total // (1024**3):.1f}GB)")
    
    # Disque
    disk = psutil.disk_usage('/')
    print(f"üíø Disque: {disk.percent:.1f}% ({disk.used // (1024**3):.1f}GB / {disk.total // (1024**3):.1f}GB)")
    
    # Charge syst√®me
    load_avg = psutil.getloadavg()
    print(f"üìä Charge: {load_avg[0]:.2f}, {load_avg[1]:.2f}, {load_avg[2]:.2f}")
    
    return {
        'cpu_percent': cpu_percent,
        'memory_percent': memory.percent,
        'disk_percent': disk.percent,
        'load_avg': load_avg
    }

def check_ai_services():
    """V√©rification des services IA"""
    print("\\nüß† Services IA")
    print("-" * 15)
    
    services = [
        "energy-ai-predictor",
        "energy-scenarios",
        "weather-ml", 
        "cost-optimizer"
    ]
    
    service_status = {}
    
    for service in services:
        try:
            # Status du service
            result = subprocess.run(
                ["systemctl", "is-active", service],
                capture_output=True,
                text=True
            )
            
            status = result.stdout.strip()
            
            # Utilisation m√©moire du service
            try:
                mem_result = subprocess.run(
                    ["systemctl", "show", service, "--property=MemoryCurrent"],
                    capture_output=True,
                    text=True
                )
                
                memory_line = mem_result.stdout.strip()
                if "MemoryCurrent=" in memory_line:
                    memory_bytes = int(memory_line.split("=")[1])
                    memory_mb = memory_bytes / (1024 * 1024)
                else:
                    memory_mb = 0
                    
            except:
                memory_mb = 0
            
            icon = "‚úÖ" if status == "active" else "‚ùå"
            print(f"{icon} {service}: {status} ({memory_mb:.1f}MB)")
            
            service_status[service] = {
                'status': status,
                'memory_mb': memory_mb,
                'active': status == 'active'
            }
            
        except Exception as e:
            print(f"‚ùå {service}: Erreur - {e}")
            service_status[service] = {
                'status': 'error',
                'memory_mb': 0,
                'active': False
            }
    
    return service_status

def check_ai_performance():
    """V√©rification des performances IA"""
    print("\\nüìà Performance IA")
    print("-" * 16)
    
    performance_data = {
        'predictions_24h': 0,
        'scenarios_executed': 0,
        'avg_response_time': 0,
        'error_rate': 0
    }
    
    # Simuler m√©triques de performance (en production, r√©cup√©rer depuis InfluxDB)
    try:
        # V√©rifier logs r√©cents pour compter activit√©
        services_activity = []
        
        for service in ["energy-ai-predictor", "energy-scenarios", "weather-ml", "cost-optimizer"]:
            try:
                result = subprocess.run(
                    ["journalctl", "-u", service, "--since", "24 hours ago", "--grep", "‚úÖ"],
                    capture_output=True,
                    text=True
                )
                
                activity_count = len(result.stdout.strip().split('\\n')) if result.stdout.strip() else 0
                services_activity.append(activity_count)
                
            except:
                services_activity.append(0)
        
        performance_data['predictions_24h'] = services_activity[0]  # Predictor
        performance_data['scenarios_executed'] = services_activity[1]  # Scenarios
        
        print(f"üîÆ Pr√©dictions 24h: {performance_data['predictions_24h']}")
        print(f"üéØ Sc√©narios ex√©cut√©s: {performance_data['scenarios_executed']}")
        print(f"‚ö° Temps r√©ponse moyen: {performance_data['avg_response_time']:.2f}ms")
        print(f"üö® Taux d'erreur: {performance_data['error_rate']:.1f}%")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Impossible de r√©cup√©rer m√©triques: {e}")
    
    return performance_data

def check_data_flow():
    """V√©rification du flux de donn√©es"""
    print("\\nüìä Flux de donn√©es")
    print("-" * 17)
    
    # Test connectivit√© MQTT
    mqtt_status = test_mqtt_connectivity()
    
    # Test connectivit√© InfluxDB
    influxdb_status = test_influxdb_connectivity()
    
    print(f"üì° MQTT: {'‚úÖ OK' if mqtt_status else '‚ùå KO'}")
    print(f"üóÑÔ∏è InfluxDB: {'‚úÖ OK' if influxdb_status else '‚ùå KO'}")
    
    return {
        'mqtt_ok': mqtt_status,
        'influxdb_ok': influxdb_status
    }

def test_mqtt_connectivity():
    """Test de connectivit√© MQTT"""
    try:
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        result = sock.connect_ex(("{{ mqtt_broker_host | default('localhost') }}", 1883))
        sock.close()
        return result == 0
    except:
        return False

def test_influxdb_connectivity():
    """Test de connectivit√© InfluxDB"""
    try:
        response = requests.get(
            "{{ influxdb_url | default('http://localhost:8086') }}/health",
            timeout=5
        )
        return response.status_code == 200
    except:
        return False

def generate_performance_score(system_resources, service_status, performance_data, data_flow):
    """Calcul du score de performance global"""
    
    score = 100
    
    # P√©nalit√©s syst√®me
    if system_resources['cpu_percent'] > 80:
        score -= 15
    elif system_resources['cpu_percent'] > 60:
        score -= 5
        
    if system_resources['memory_percent'] > 85:
        score -= 15
    elif system_resources['memory_percent'] > 70:
        score -= 5
        
    if system_resources['disk_percent'] > 90:
        score -= 20
    elif system_resources['disk_percent'] > 80:
        score -= 10
    
    # P√©nalit√©s services
    active_services = sum(1 for s in service_status.values() if s['active'])
    total_services = len(service_status)
    
    if active_services < total_services:
        score -= (total_services - active_services) * 15
    
    # P√©nalit√©s flux de donn√©es
    if not data_flow['mqtt_ok']:
        score -= 20
    if not data_flow['influxdb_ok']:
        score -= 15
    
    # P√©nalit√©s performance
    if performance_data['predictions_24h'] == 0:
        score -= 10
    
    score = max(0, min(100, score))
    
    if score >= 90:
        level = "excellent"
    elif score >= 75:
        level = "good"
    elif score >= 50:
        level = "acceptable"
    else:
        level = "poor"
    
    return score, level

def main():
    """Point d'entr√©e principal"""
    print("üìä PERFORMANCE MONITOR - ENERGY AI")
    print("=" * 50)
    print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # Collecte des m√©triques
        system_resources = check_system_resources()
        service_status = check_ai_services()
        performance_data = check_ai_performance()
        data_flow = check_data_flow()
        
        # Calcul du score global
        score, level = generate_performance_score(
            system_resources, service_status, performance_data, data_flow
        )
        
        print(f"\\nüéØ SCORE GLOBAL: {score}/100 ({level.upper()})")
        print("=" * 50)
        
        # Recommandations
        print("\\nüí° Recommandations:")
        
        if system_resources['cpu_percent'] > 70:
            print("   üîß CPU √©lev√© - V√©rifier les processus consommateurs")
            
        if system_resources['memory_percent'] > 80:
            print("   üíæ M√©moire √©lev√©e - Consid√©rer l'augmentation de RAM")
            
        if system_resources['disk_percent'] > 85:
            print("   üíø Disque plein - Nettoyer les logs anciens")
        
        inactive_services = [name for name, status in service_status.items() if not status['active']]
        if inactive_services:
            print(f"   ‚öôÔ∏è Services inactifs: {', '.join(inactive_services)}")
            
        if not data_flow['mqtt_ok']:
            print("   üì° Probl√®me MQTT - V√©rifier le broker")
            
        if not data_flow['influxdb_ok']:
            print("   üóÑÔ∏è Probl√®me InfluxDB - V√©rifier la base de donn√©es")
        
        if performance_data['predictions_24h'] < 50:
            print("   üîÆ Faible activit√© pr√©dictions - V√©rifier la configuration")
        
        if score >= 90:
            print("   ‚úÖ Syst√®me optimal - Continuer le monitoring")
        
        # Sauvegarde rapport
        report = {
            'timestamp': datetime.now().isoformat(),
            'score': score,
            'level': level,
            'system_resources': system_resources,
            'service_status': service_status,
            'performance_data': performance_data,
            'data_flow': data_flow
        }
        
        report_path = "{{ energy_ai_paths.logs | default('/opt/energy-ai/logs') }}/performance_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\\nüìÑ Rapport d√©taill√©: {report_path}")
        
        return 0 if score >= 50 else 1
        
    except Exception as e:
        print(f"‚ùå Erreur lors du monitoring: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)